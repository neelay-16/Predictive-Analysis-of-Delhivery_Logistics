{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da8c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_logistics_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c14338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the selected features data\n",
    "selected_features_df = pd.read_csv('X_ridge_selected.csv')  # Replace with your feature selection file path\n",
    "target_variable = 'is_cutoff'  # Replace with your target variable name if different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc7cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your original DataFrame with the target variable\n",
    "y = df[target_variable]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ef4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 4. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_features_df, y, test_size=0.2, random_state=42\n",
    ")  # Adjust test_size and random_state as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac037180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.5863 - accuracy: 0.8235 - val_loss: 0.2527 - val_accuracy: 0.8453 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "2898/2898 [==============================] - 50s 17ms/step - loss: 0.1775 - accuracy: 0.8415 - val_loss: 0.1481 - val_accuracy: 0.8368 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1430 - accuracy: 0.8417 - val_loss: 0.1362 - val_accuracy: 0.8471 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1373 - accuracy: 0.8432 - val_loss: 0.1305 - val_accuracy: 0.8476 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1339 - accuracy: 0.8451 - val_loss: 0.1269 - val_accuracy: 0.8525 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "2898/2898 [==============================] - 53s 18ms/step - loss: 0.1302 - accuracy: 0.8464 - val_loss: 0.1241 - val_accuracy: 0.8517 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1266 - accuracy: 0.8482 - val_loss: 0.1206 - val_accuracy: 0.8547 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1251 - accuracy: 0.8505 - val_loss: 0.1184 - val_accuracy: 0.8549 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1236 - accuracy: 0.8499 - val_loss: 0.1189 - val_accuracy: 0.8554 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1218 - accuracy: 0.8516 - val_loss: 0.1167 - val_accuracy: 0.8558 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1214 - accuracy: 0.8511 - val_loss: 0.1154 - val_accuracy: 0.8569 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1197 - accuracy: 0.8533 - val_loss: 0.1135 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "2898/2898 [==============================] - 53s 18ms/step - loss: 0.1195 - accuracy: 0.8534 - val_loss: 0.1139 - val_accuracy: 0.8595 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1188 - accuracy: 0.8529 - val_loss: 0.1125 - val_accuracy: 0.8600 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "2898/2898 [==============================] - 54s 18ms/step - loss: 0.1181 - accuracy: 0.8547 - val_loss: 0.1127 - val_accuracy: 0.8589 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1182 - accuracy: 0.8547 - val_loss: 0.1151 - val_accuracy: 0.8593 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1179 - accuracy: 0.8556 - val_loss: 0.1123 - val_accuracy: 0.8629 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1175 - accuracy: 0.8550 - val_loss: 0.1104 - val_accuracy: 0.8619 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1172 - accuracy: 0.8551 - val_loss: 0.1148 - val_accuracy: 0.8559 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "2898/2898 [==============================] - 50s 17ms/step - loss: 0.1166 - accuracy: 0.8564 - val_loss: 0.1135 - val_accuracy: 0.8591 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1166 - accuracy: 0.8565 - val_loss: 0.1117 - val_accuracy: 0.8630 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1168 - accuracy: 0.8567 - val_loss: 0.1129 - val_accuracy: 0.8599 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1160 - accuracy: 0.8575 - val_loss: 0.1088 - val_accuracy: 0.8648 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.1157 - accuracy: 0.8570 - val_loss: 0.1100 - val_accuracy: 0.8602 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.1160 - accuracy: 0.8572 - val_loss: 0.1103 - val_accuracy: 0.8639 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1160 - accuracy: 0.8570 - val_loss: 0.1110 - val_accuracy: 0.8643 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.1160 - accuracy: 0.8576 - val_loss: 0.1104 - val_accuracy: 0.8651 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.1157 - accuracy: 0.8576 - val_loss: 0.1109 - val_accuracy: 0.8580 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1089 - accuracy: 0.8655 - val_loss: 0.1006 - val_accuracy: 0.8704 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1051 - accuracy: 0.8706 - val_loss: 0.0969 - val_accuracy: 0.8805 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1024 - accuracy: 0.8762 - val_loss: 0.0926 - val_accuracy: 0.8917 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "2898/2898 [==============================] - 55s 19ms/step - loss: 0.1014 - accuracy: 0.8783 - val_loss: 0.0927 - val_accuracy: 0.8937 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.1006 - accuracy: 0.8790 - val_loss: 0.0929 - val_accuracy: 0.8905 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.0995 - accuracy: 0.8814 - val_loss: 0.0898 - val_accuracy: 0.8957 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.0994 - accuracy: 0.8814 - val_loss: 0.0894 - val_accuracy: 0.8971 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "2898/2898 [==============================] - 54s 19ms/step - loss: 0.0988 - accuracy: 0.8830 - val_loss: 0.0896 - val_accuracy: 0.8988 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.0987 - accuracy: 0.8838 - val_loss: 0.0951 - val_accuracy: 0.8852 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "2898/2898 [==============================] - 53s 18ms/step - loss: 0.0989 - accuracy: 0.8834 - val_loss: 0.0898 - val_accuracy: 0.8953 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0988 - accuracy: 0.8833 - val_loss: 0.0902 - val_accuracy: 0.8975 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0983 - accuracy: 0.8838 - val_loss: 0.0875 - val_accuracy: 0.9025 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0975 - accuracy: 0.8864 - val_loss: 0.0904 - val_accuracy: 0.8963 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.0974 - accuracy: 0.8858 - val_loss: 0.0866 - val_accuracy: 0.9008 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0972 - accuracy: 0.8863 - val_loss: 0.0874 - val_accuracy: 0.9015 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "2898/2898 [==============================] - 52s 18ms/step - loss: 0.0974 - accuracy: 0.8861 - val_loss: 0.0906 - val_accuracy: 0.8970 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0971 - accuracy: 0.8876 - val_loss: 0.0890 - val_accuracy: 0.9011 - lr: 2.5000e-04\n",
      "Epoch 46/100\n",
      "2898/2898 [==============================] - 60s 21ms/step - loss: 0.0976 - accuracy: 0.8861 - val_loss: 0.0894 - val_accuracy: 0.8998 - lr: 2.5000e-04\n",
      "Epoch 47/100\n",
      "2898/2898 [==============================] - 59s 20ms/step - loss: 0.0978 - accuracy: 0.8868 - val_loss: 0.0880 - val_accuracy: 0.8993 - lr: 2.5000e-04\n",
      "Epoch 48/100\n",
      "2898/2898 [==============================] - 59s 20ms/step - loss: 0.0904 - accuracy: 0.8951 - val_loss: 0.0789 - val_accuracy: 0.9125 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0861 - accuracy: 0.9009 - val_loss: 0.0771 - val_accuracy: 0.9138 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0856 - accuracy: 0.9018 - val_loss: 0.0775 - val_accuracy: 0.9131 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "2898/2898 [==============================] - 59s 20ms/step - loss: 0.0844 - accuracy: 0.9033 - val_loss: 0.0771 - val_accuracy: 0.9135 - lr: 1.2500e-04\n",
      "Epoch 52/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0846 - accuracy: 0.9026 - val_loss: 0.0775 - val_accuracy: 0.9112 - lr: 1.2500e-04\n",
      "Epoch 53/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0829 - accuracy: 0.9056 - val_loss: 0.0739 - val_accuracy: 0.9165 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0826 - accuracy: 0.9057 - val_loss: 0.0761 - val_accuracy: 0.9145 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0825 - accuracy: 0.9056 - val_loss: 0.0751 - val_accuracy: 0.9157 - lr: 1.2500e-04\n",
      "Epoch 56/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0820 - accuracy: 0.9065 - val_loss: 0.0798 - val_accuracy: 0.9100 - lr: 1.2500e-04\n",
      "Epoch 57/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0820 - accuracy: 0.9067 - val_loss: 0.0740 - val_accuracy: 0.9174 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0818 - accuracy: 0.9071 - val_loss: 0.0733 - val_accuracy: 0.9179 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0818 - accuracy: 0.9075 - val_loss: 0.0731 - val_accuracy: 0.9179 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0810 - accuracy: 0.9079 - val_loss: 0.0734 - val_accuracy: 0.9177 - lr: 1.2500e-04\n",
      "Epoch 61/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0810 - accuracy: 0.9085 - val_loss: 0.0738 - val_accuracy: 0.9154 - lr: 1.2500e-04\n",
      "Epoch 62/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0813 - accuracy: 0.9072 - val_loss: 0.0730 - val_accuracy: 0.9175 - lr: 1.2500e-04\n",
      "Epoch 63/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0809 - accuracy: 0.9089 - val_loss: 0.0717 - val_accuracy: 0.9205 - lr: 1.2500e-04\n",
      "Epoch 64/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0807 - accuracy: 0.9089 - val_loss: 0.0720 - val_accuracy: 0.9191 - lr: 1.2500e-04\n",
      "Epoch 65/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0806 - accuracy: 0.9097 - val_loss: 0.0723 - val_accuracy: 0.9199 - lr: 1.2500e-04\n",
      "Epoch 66/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0802 - accuracy: 0.9093 - val_loss: 0.0760 - val_accuracy: 0.9139 - lr: 1.2500e-04\n",
      "Epoch 67/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0799 - accuracy: 0.9100 - val_loss: 0.0714 - val_accuracy: 0.9210 - lr: 1.2500e-04\n",
      "Epoch 68/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0805 - accuracy: 0.9089 - val_loss: 0.0745 - val_accuracy: 0.9152 - lr: 1.2500e-04\n",
      "Epoch 69/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0801 - accuracy: 0.9099 - val_loss: 0.0719 - val_accuracy: 0.9198 - lr: 1.2500e-04\n",
      "Epoch 70/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0792 - accuracy: 0.9113 - val_loss: 0.0717 - val_accuracy: 0.9209 - lr: 1.2500e-04\n",
      "Epoch 71/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0800 - accuracy: 0.9099 - val_loss: 0.0716 - val_accuracy: 0.9195 - lr: 1.2500e-04\n",
      "Epoch 72/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0788 - accuracy: 0.9116 - val_loss: 0.0707 - val_accuracy: 0.9220 - lr: 1.2500e-04\n",
      "Epoch 73/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0794 - accuracy: 0.9112 - val_loss: 0.0710 - val_accuracy: 0.9212 - lr: 1.2500e-04\n",
      "Epoch 74/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0801 - accuracy: 0.9107 - val_loss: 0.0711 - val_accuracy: 0.9199 - lr: 1.2500e-04\n",
      "Epoch 75/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0790 - accuracy: 0.9111 - val_loss: 0.0701 - val_accuracy: 0.9240 - lr: 1.2500e-04\n",
      "Epoch 76/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0793 - accuracy: 0.9105 - val_loss: 0.0708 - val_accuracy: 0.9227 - lr: 1.2500e-04\n",
      "Epoch 77/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0789 - accuracy: 0.9116 - val_loss: 0.0686 - val_accuracy: 0.9248 - lr: 1.2500e-04\n",
      "Epoch 78/100\n",
      "2898/2898 [==============================] - 73s 25ms/step - loss: 0.0792 - accuracy: 0.9114 - val_loss: 0.0686 - val_accuracy: 0.9251 - lr: 1.2500e-04\n",
      "Epoch 79/100\n",
      "2898/2898 [==============================] - 69s 24ms/step - loss: 0.0782 - accuracy: 0.9131 - val_loss: 0.0699 - val_accuracy: 0.9217 - lr: 1.2500e-04\n",
      "Epoch 80/100\n",
      "2898/2898 [==============================] - 56s 19ms/step - loss: 0.0786 - accuracy: 0.9121 - val_loss: 0.0684 - val_accuracy: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 81/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0788 - accuracy: 0.9119 - val_loss: 0.0733 - val_accuracy: 0.9166 - lr: 1.2500e-04\n",
      "Epoch 82/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0786 - accuracy: 0.9118 - val_loss: 0.0704 - val_accuracy: 0.9222 - lr: 1.2500e-04\n",
      "Epoch 83/100\n",
      "2898/2898 [==============================] - 58s 20ms/step - loss: 0.0783 - accuracy: 0.9124 - val_loss: 0.0695 - val_accuracy: 0.9232 - lr: 1.2500e-04\n",
      "Epoch 84/100\n",
      "2898/2898 [==============================] - 56s 19ms/step - loss: 0.0782 - accuracy: 0.9125 - val_loss: 0.0688 - val_accuracy: 0.9255 - lr: 1.2500e-04\n",
      "Epoch 85/100\n",
      "2898/2898 [==============================] - 57s 19ms/step - loss: 0.0781 - accuracy: 0.9128 - val_loss: 0.0685 - val_accuracy: 0.9259 - lr: 1.2500e-04\n",
      "Epoch 86/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0722 - accuracy: 0.9214 - val_loss: 0.0635 - val_accuracy: 0.9331 - lr: 6.2500e-05\n",
      "Epoch 87/100\n",
      "2898/2898 [==============================] - 57s 20ms/step - loss: 0.0699 - accuracy: 0.9239 - val_loss: 0.0621 - val_accuracy: 0.9344 - lr: 6.2500e-05\n",
      "Epoch 88/100\n",
      "2898/2898 [==============================] - 54s 18ms/step - loss: 0.0693 - accuracy: 0.9241 - val_loss: 0.0634 - val_accuracy: 0.9315 - lr: 6.2500e-05\n",
      "Epoch 89/100\n",
      "2898/2898 [==============================] - 51s 17ms/step - loss: 0.0685 - accuracy: 0.9251 - val_loss: 0.0624 - val_accuracy: 0.9321 - lr: 6.2500e-05\n",
      "Epoch 90/100\n",
      "2898/2898 [==============================] - 51s 17ms/step - loss: 0.0680 - accuracy: 0.9259 - val_loss: 0.0606 - val_accuracy: 0.9365 - lr: 6.2500e-05\n",
      "Epoch 91/100\n",
      "2898/2898 [==============================] - 51s 17ms/step - loss: 0.0679 - accuracy: 0.9257 - val_loss: 0.0592 - val_accuracy: 0.9371 - lr: 6.2500e-05\n",
      "Epoch 92/100\n",
      "2898/2898 [==============================] - 51s 17ms/step - loss: 0.0673 - accuracy: 0.9270 - val_loss: 0.0613 - val_accuracy: 0.9348 - lr: 6.2500e-05\n",
      "Epoch 93/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0678 - accuracy: 0.9262 - val_loss: 0.0612 - val_accuracy: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 94/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0669 - accuracy: 0.9263 - val_loss: 0.0585 - val_accuracy: 0.9363 - lr: 6.2500e-05\n",
      "Epoch 95/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0672 - accuracy: 0.9265 - val_loss: 0.0593 - val_accuracy: 0.9350 - lr: 6.2500e-05\n",
      "Epoch 96/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0672 - accuracy: 0.9264 - val_loss: 0.0594 - val_accuracy: 0.9364 - lr: 6.2500e-05\n",
      "Epoch 97/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0672 - accuracy: 0.9262 - val_loss: 0.0599 - val_accuracy: 0.9364 - lr: 6.2500e-05\n",
      "Epoch 98/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0672 - accuracy: 0.9265 - val_loss: 0.0615 - val_accuracy: 0.9328 - lr: 6.2500e-05\n",
      "Epoch 99/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0668 - accuracy: 0.9263 - val_loss: 0.0584 - val_accuracy: 0.9386 - lr: 6.2500e-05\n",
      "Epoch 100/100\n",
      "2898/2898 [==============================] - 51s 18ms/step - loss: 0.0669 - accuracy: 0.9268 - val_loss: 0.0582 - val_accuracy: 0.9381 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(3016,), \n",
    "           kernel_regularizer=l2(0.001),  # L2 regularization\n",
    "           kernel_initializer='he_normal'),  # Better weight initialization\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Increased dropout rate\n",
    "    \n",
    "    Dense(256, activation='relu', \n",
    "          kernel_regularizer=l2(0.001),\n",
    "          kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(128, activation='relu', \n",
    "          kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Adjust based on your output\n",
    "])\n",
    "\n",
    "# Compile with advanced optimizer settings\n",
    "optimizer = Adam(learning_rate=0.0005,  # Reduced learning rate\n",
    "                 beta_1=0.9,\n",
    "                 beta_2=0.999,\n",
    "                 epsilon=1e-07)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Advanced training callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=15,  # Increased patience\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.0001\n",
    ")\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,  # Reduce learning rate\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training with more epochs and callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Increased number of epochs\n",
    "    batch_size=32,  # Experiment with batch size\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, lr_reducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479f69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 3016),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'},\n",
       "   'registered_name': None},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'batch_input_shape': (None, 3016),\n",
       "    'units': 512,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'HeNormal',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': {'module': 'keras.regularizers',\n",
       "     'class_name': 'L2',\n",
       "     'config': {'l2': 0.0010000000474974513},\n",
       "     'registered_name': None},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 3016)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': [1],\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'gamma_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Ones',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'moving_mean_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'moving_variance_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Ones',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 512)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.4,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 512)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'HeNormal',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': {'module': 'keras.regularizers',\n",
       "     'class_name': 'L2',\n",
       "     'config': {'l2': 0.0010000000474974513},\n",
       "     'registered_name': None},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 512)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': [1],\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'gamma_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Ones',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'moving_mean_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'moving_variance_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Ones',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 256)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.3,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 256)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': {'module': 'keras.regularizers',\n",
       "     'class_name': 'L2',\n",
       "     'config': {'l2': 0.0010000000474974513},\n",
       "     'registered_name': None},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 256)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.2,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 128)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 64,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 128)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 64)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd524f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               1544704   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1722369 (6.57 MB)\n",
      "Trainable params: 1720833 (6.56 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45402d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9d9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a33ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
